<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=theme-color><title>James Robb &#183; Building a Multi-Tenant Metrics Pipeline for Thousands of Clients</title><meta name=title content="Building a Multi-Tenant Metrics Pipeline for Thousands of Clients &#183; James Robb"><meta name=keywords content="architecture,software,"><link rel=canonical href=http://jamesrobb.ca/projects/metrics_pipeline/><link type=text/css rel=stylesheet href=/css/main.bundle.min.c2a67afef778335242b00ad2132d4aaa34a0a577c04da3eedf4c5d4737ee67866edbdc57787e966dd230ed9e3417256118a65acd2db0fd1ca28ec3e8e32b11d2.css integrity="sha512-wqZ6/vd4M1JCsArSEy1KqjSgpXfATaPu30xdRzfuZ4Zu29xXeH6WbdIw7Z40FyVhGKZazS2w/RyijsPo4ysR0g=="><script type=text/javascript src=/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js integrity="sha512-b0EXSzoFtoCCD+CMrb+l+3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.a187118b41a60744310065c567365de85730c8495301d0ebae41810cc6f7a47432b1de7d4f3b11338959f1ac50c266be6b4b73acf6bf770016eb59b602cc1aa0.js integrity="sha512-oYcRi0GmB0QxAGXFZzZd6FcwyElTAdDrrkGBDMb3pHQysd59TzsRM4lZ8axQwma+a0tzrPa/dwAW61m2AswaoA==" data-copy=Copy data-copied=Copied></script><script src=/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7+kfJ6kKCJxQGC+8wm+Bz9JucDjDTGNew=="></script><meta property="og:url" content="http://jamesrobb.ca/projects/metrics_pipeline/"><meta property="og:site_name" content="James Robb"><meta property="og:title" content="Building a Multi-Tenant Metrics Pipeline for Thousands of Clients"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2026-01-21T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-21T00:00:00+00:00"><meta property="article:tag" content="Architecture"><meta property="article:tag" content="Software"><meta name=twitter:card content="summary"><meta name=twitter:title content="Building a Multi-Tenant Metrics Pipeline for Thousands of Clients"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Projects","name":"Building a Multi-Tenant Metrics Pipeline for Thousands of Clients","headline":"Building a Multi-Tenant Metrics Pipeline for Thousands of Clients","inLanguage":"en","url":"http:\/\/jamesrobb.ca\/projects\/metrics_pipeline\/","author":{"@type":"Person","name":"James Robb"},"copyrightYear":"2026","dateCreated":"2026-01-21T00:00:00\u002b00:00","datePublished":"2026-01-21T00:00:00\u002b00:00","dateModified":"2026-01-21T00:00:00\u002b00:00","keywords":["architecture","software"],"mainEntityOfPage":"true","wordCount":"3626"}]</script><meta name=author content="James Robb"><link href=https://gitlab.com/jamesrobb rel=me><link href=https://www.linkedin.com/in/james-robb-15823992/ rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
Skip to main content</a></div><div class=min-h-100></div><div class="fixed inset-x-0 z-100"><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32"><div class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3 pt-[2px] pr-0 pb-[3px] pl-0"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-2xl font-bold">James Robb</a></nav><nav class="hidden lg:flex items-center gap-x-5 md:ml-12 h-12"><a href=/projects/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Projects title=Projects><p class="text-base font-medium">Projects</p></a><a href=/technical_writing/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label="Technical Writing" title="Technical Writing"><p class="text-base font-medium">Technical Writing</p></a><a href=/cv/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=CV title="Curriculum Vitae"><p class="text-base font-medium">CV</p></a><a href=/tags/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Tags title=Tags><p class="text-base font-medium">Tags</p></a><a href=https://github.com/jamesrobb target=_blank class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=github title><span><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a href=https://www.linkedin.com/in/jtrobb/ target=_blank class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=linkedin title><span><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a><a href=mailto:me@jamesrobb.ca class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=email title><span><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></span></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></nav><div class="flex lg:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title="Search (/)">
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button></div></div><div class="-my-2 lg:hidden"><div id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50 pt-[5px]"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none text-end max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/projects/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Projects title=Projects><p class="text-bg font-bg">Projects</p></a></li><li class=mt-1><a href=/technical_writing/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label="Technical Writing" title="Technical Writing"><p class="text-bg font-bg">Technical Writing</p></a></li><li class=mt-1><a href=/cv/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=CV title="Curriculum Vitae"><p class="text-bg font-bg">CV</p></a></li><li class=mt-1><a href=/tags/ class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=Tags title=Tags><p class="text-bg font-bg">Tags</p></a></li><li class=mt-1><a href=https://github.com/jamesrobb target=_blank class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=github title><div><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></div></a></li><li class=mt-1><a href=https://www.linkedin.com/in/jtrobb/ target=_blank class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=linkedin title><div><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></div></a></li><li class=mt-1><a href=mailto:me@jamesrobb.ca class="flex items-center hover:text-primary-600 dark:hover:text-primary-400" aria-label=email title><div><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></div></a></li></ul></div></div></div></div></div></div><script type=text/javascript src=/js/background-blur.min.00a57c73ea12f2cab2980c3c3d649e89f6d82f190f74bbe2b67f2f5e39ab7d032ece47086400ca05396758aace13299da49aca43ea643d2625e62c506267a169.js integrity="sha512-AKV8c+oS8sqymAw8PWSeifbYLxkPdLvitn8vXjmrfQMuzkcIZADKBTlnWKrOEymdpJrKQ+pkPSYl5ixQYmehaQ==" data-blur-id=menu-blur></script><div class="relative flex flex-col grow"><div class="fixed bottom-0 right-0 w-full -z-10 lg:w-3-4 max-w-800"><img id=background-image class="nozoom mt-0 mr-0 mb-0 ml-0 h-auto w-full object-cover" src=/img/message.svg role=presentation></div><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Building a Multi-Tenant Metrics Pipeline for Thousands of Clients</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2026-01-21T00:00:00+00:00>2026 January 21</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">18 mins</span></div><div class="flex flex-row flex-wrap items-center"><a class="relative mt-[0.5rem] me-2" href=/tags/architecture/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Architecture
</span></span></a><a class="relative mt-[0.5rem] me-2" href=/tags/software/><span class="flex cursor-pointer"><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Software</span></span></a></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last lg:ps-8 lg:max-w-2xs"><div class="toc ps-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-auto overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg -ms-5 ps-5 pe-2 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#requirements>Requirements</a></li><li><a href=#heimdall>Heimdall</a><ul><li><a href=#overview>Overview</a></li><li><a href=#egress>Egress</a></li><li><a href=#ingress>Ingress</a></li></ul></li><li><a href=#thanos>Thanos</a><ul><li><a href=#plumbing>Plumbing</a></li><li><a href=#scalability-and-performance>Scalability and Performance</a></li></ul></li><li><a href=#grafana>Grafana</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg -ms-5 ps-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 -ms-5 ps-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 border-s-1 -ms-5 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#requirements>Requirements</a></li><li><a href=#heimdall>Heimdall</a><ul><li><a href=#overview>Overview</a></li><li><a href=#egress>Egress</a></li><li><a href=#ingress>Ingress</a></li></ul></li><li><a href=#thanos>Thanos</a><ul><li><a href=#plumbing>Plumbing</a></li><li><a href=#scalability-and-performance>Scalability and Performance</a></li></ul></li><li><a href=#grafana>Grafana</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h2 class="relative group">Introduction<div id=introduction class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#introduction aria-label=Anchor>#</a></span></h2><p>The last big project I worked on during my time at <a href=https://yellowbrick.com/ target=_blank>Yellowbrick</a> was a brand new observability stack for the core product, an <a href=https://en.wikipedia.org/wiki/Online_analytical_processing target=_blank>OLAP</a> data warehouse. The company had finished a big push to create a cloud version of the product (which up to that point ran on a custom appliance) and we were finding that our mostly log-driven approach to observability was falling short. Diagnosing performance issues or failures took too much time and effort, and cloud customers had much different expectations on how to observe the health of their systems than our appliance customers.</p><p>The solution, at a high level, was straightforward: instrument the product to expose <a href=https://prometheus.io/ target=_blank>Prometheus</a> metrics, and use <a href=https://grafana.com/ target=_blank>Grafana</a> to visualize them. Prometheus and Grafana are ubiquitous observability tools and would allow both developers and customers to get quick and meaningful insight into a running system. Reality was more complicated. In broad strokes, the data warehouse consists of three main components: the query planner, the compiler and resource manager, and the execution engine. These components were developed in three different languages, at different times, and by different people. The specifics of how we instrumented them are out of scope for what I want to talk about here, but it took several very talented engineers considerable time and effort to do.</p><p>One of the core expectations of this project was that we could see all metrics collected on all Yellowbrick systems, customer and internal, in real time. Several posts could be written about how this project as a whole was designed and implemented, but here I want to focus on the metrics transport - that is, how we reliably got metrics from all running Yellowbrick systems into a centralized <a href=https://thanos.io/ target=_blank>Thanos</a> deployment, and how we visualized them.</p><h2 class="relative group">Requirements<div id=requirements class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#requirements aria-label=Anchor>#</a></span></h2><p>From here, we assume that the product is fully instrumented and exposes useful metrics via a collection of Prometheus-scrapable HTTP endpoints. The requirements for the metrics transport were:</p><ol><li>The metrics must be available in real time, or close to it.</li><li>We could not lose data - if our infrastructure was unavailable, metrics needed to queue until transport resumed.</li><li>We had to be able to remotely configure what metrics are sent to Thanos.</li><li>Only data from systems with a valid license should be ingested.</li><li>Support thousands of systems reporting metrics in parallel.</li><li>Use the same dashboards we shipped to customers; dogfooding ensures they remain useful and polished.</li></ol><p>Given these requirements, the naive approach of having Prometheus write directly to Thanos breaks down. Prometheus can be configured to write directly to Thanos using RWP (<a href=https://prometheus.io/docs/specs/prw/remote_write_spec/ target=_blank>Remote Write Protocol</a>), but using Prometheus&rsquo; RWP functionality alone can&rsquo;t satisfy requirements 2 and 3, and while satisfying requirement 4 is technically possible, doing so is fragile in practice.</p><p>When Prometheus writes to a remote endpoint using RWP, it maintains in-memory queues to hold the samples. If the remote endpoint is unavailable for too long, Prometheus eventually starts discarding the oldest samples in the queues. How long &ldquo;too long&rdquo; is will depend on things like how many samples Prometheus is attempting to send and how much memory is available to Prometheus. In practice, this is on the order of minutes or hours, not days, and so satisfying requirement 2 isn&rsquo;t feasible.</p><p>The fact that Prometheus&rsquo; configuration is static (it&rsquo;s a file on disk) also presents issues. We felt that any approach that required rewriting Prometheus&rsquo; configuration file, be it in response to license changes or changes to what metrics we want to collect, opened us up to too much operational risk. If there was any problem in the configuration, we could not only interrupt the flow of metrics to Thanos, but also prevent Prometheus from coming online at all. For this reason, we could not satisfy requirements 3 and 4 with the naive approach.</p><h2 class="relative group">Heimdall<div id=heimdall class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#heimdall aria-label=Anchor>#</a></span></h2><p>To satisfy all the requirements in an operationally stable way, we developed Heimdall. It comprises two binaries, Heimdall Egress and Heimdall Ingress. I built Heimdall in Golang because I&rsquo;ve found it to be a wonderful programming language for tasks involving concurrency and parallelism (and I just genuinely enjoy working in it). The egress binary runs alongside Prometheus in the customer&rsquo;s Kubernetes cluster and the ingress binary on &ldquo;the mothership&rdquo;. The mothership is a large virtual machine that runs Thanos, Heimdall Ingress, Grafana, and a few other supporting services.</p><h3 class="relative group">Overview<div id=overview class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#overview aria-label=Anchor>#</a></span></h3><p>The two binaries work together to relay metrics from the customer&rsquo;s Prometheus into Thanos. From the perspective of Prometheus and Thanos the ingress and egress binaries are just services that speak RWP, but to satisfy all our requirements they needed to do a bit more.</p><p>The egress binary is responsible for:</p><ul><li>Relaying metrics it receives from Prometheus to the ingress binary.</li><li>Persisting metrics to a disk-based FIFO queue until the ingress binary confirms Thanos has accepted them.</li><li>Filtering metrics with a whitelist and blacklist regex.</li><li>Finding and attaching the customer license to each payload sent to the ingress binary.</li></ul><p>The ingress binary is responsible for:</p><ul><li>Relaying metrics it receives from the egress binary to Thanos.</li><li>Checking that payloads have a valid license attached.</li><li>Maintaining a whitelist and blacklist regex per tenant (i.e., customer) that the egress binary can query for.</li></ul><p>Before we go any further, let&rsquo;s see how data flows through this system. It&rsquo;ll do wonders to keep us on the same page as we dive into the details. The arrows reflect the flow of data.</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="Metrics flow from customer system to Thanos" width=1342 height=1262 src=/projects/metrics_pipeline/heimdall_overview_hu_6346b07b64f70b5.png srcset="/projects/metrics_pipeline/heimdall_overview_hu_6346b07b64f70b5.png 800w, /projects/metrics_pipeline/heimdall_overview_hu_b3e0efbabfcfad85.png 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/projects/metrics_pipeline/heimdall_overview.png></figure></p><p>Prometheus scrapes the various endpoints exposed by each instance of the instrumented data warehouse and relays them to the egress binary via RWP. The egress binary sends the RWP payload (after filtering it through the whitelist/blacklist) onto the ingress binary, attaching the license (<a href=https://en.wikipedia.org/wiki/JSON_Web_Token target=_blank>JWT</a>) as an HTTP header. Finally, the ingress binary sends the RWP payload to Thanos if the license is valid, and returns an HTTP 200 to the egress binary to let it know the payload has been received and can be dropped.</p><h3 class="relative group">Egress<div id=egress class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#egress aria-label=Anchor>#</a></span></h3><p>There are two important flows worth covering in the egress binary: forwarding data from Prometheus to Thanos, and fetching the whitelist and blacklist.</p><p>The high-level process for receiving and sending RWP payloads looks like this. I omit the details on retrieving a license because it&rsquo;s not very interesting - I just use the Kubernetes API to query for a configmap with a known name (and cache the result to avoid future lookup times).</p><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="Metrics flow through Heimdall Egress binary" width=2036 height=1362 src=/projects/metrics_pipeline/heimdall_egress_overview_hu_8c178710bb570de1.png srcset="/projects/metrics_pipeline/heimdall_egress_overview_hu_8c178710bb570de1.png 800w, /projects/metrics_pipeline/heimdall_egress_overview_hu_72eec10f51e106a2.png 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/projects/metrics_pipeline/heimdall_egress_overview.png></figure></p><p>When metrics come in from Prometheus, they are first fed through a whitelist and blacklist. There are two key reasons we can&rsquo;t simply ship all metrics Prometheus collects to the ingress binary:</p><ul><li>We can&rsquo;t know the volume of data a customer&rsquo;s Prometheus installation will produce, and there is no good reason to store metrics we are not interested in.</li><li>Customers might produce metrics with data they wish to keep private.</li></ul><p>The reason we have both a whitelist <em>and</em> a blacklist (which are regular expressions) is really to accommodate cases where we want all metrics of the form <code>yb_.*</code>, but don&rsquo;t want <code>yb_bad_metric</code>. Without the blacklist we would need to turn that whitelist expression into an explicit list of every metric of that form except <code>yb_bad_metric</code> - this would quickly become a headache.</p><p>To begin whitelist and blacklist filtering, the egress binary needs to unpack the RWP payload to know the metric names. Any metrics that make it through this filtering are then re-packaged and committed to the FIFO queue. In a separate thread the RWP payloads in the FIFO queue are read and unpacked again. The metric names are then hashed so we can place the data in one of <code>N</code> forwarding queues (which all execute concurrently). Metric names must be deterministically assigned to the same queue because RWP specifies (and Thanos enforces) that data sent for a metric must not have a timestamp older than data already received for that metric. If two samples with the same metric name landed in two different queues, then data could arrive at the ingress binary in the wrong chronological order. When a forwarding queue fills up (or a repeating timeout is hit), the contents of a queue are packaged as an RWP payload and sent to the ingress binary with the customer&rsquo;s license. One might say that we are doing too much work by unpacking the payload twice, but consider:</p><ul><li>To keep as much disk space available as possible for the metrics we want, it makes sense to filter before putting payloads into the FIFO queue.</li><li>Queue selection could be done here, but then the number of forwarding queues could not be changed without the risk of sending data in the wrong order.</li></ul><p>For these reasons, we pay the price of unpacking twice. I had the same concern, but after some testing I found it did not matter at all. The egress binary is mostly network-bound - the only time it used a meaningful amount of CPU was on our internal Kubernetes cluster that had hundreds of data warehouse instances running at any given time.</p><p>The reason we have more than one forwarding queue is to accommodate bigger deployments. On a typical deployment one forwarding queue is sufficient, but on large deployments or deployments where latency to the mothership was high, we found that the egress binary would struggle to keep up. In some of the worst cases we found the egress binary would fall further and further behind, but these problems disappeared with the parallelism introduced by several forwarding queues.</p><p>Moving on, the ingress binary will send back an acknowledgement or failure. There are three broad cases the egress binary has to deal with:</p><ul><li>Payload accepted: Drop the payload from the FIFO queue.</li><li>Failure but try again: Wait some time and try again, but don&rsquo;t discard from the FIFO queue. This could occur if the mothership is offline or partially degraded, for example.</li><li>Failure but don&rsquo;t try again: Drop the payload from the FIFO queue. This could occur if Thanos says the payload is malformed, in which case trying again would not help.</li></ul><p>The last thing I want to go over on the egress binary is the whitelist and blacklist. The egress binary fetches the whitelist and blacklist from the ingress binary. The egress binary includes the customer license in this request as well so the ingress binary knows which whitelist and blacklist pair to send back, as each <em>tenant</em> can have their own. From the perspective of Heimdall, a tenant is a Kubernetes cluster. The license sent to the ingress binary contains information like customer name, cloud provider, region, and Kubernetes cluster name. Using this information we can derive a unique tenant ID. If the egress binary is unable to get a whitelist and blacklist pair from the ingress binary, a broad default is used for each.</p><h3 class="relative group">Ingress<div id=ingress class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#ingress aria-label=Anchor>#</a></span></h3><p>Of the two binaries, Heimdall Ingress is the simpler one. It just forwards data to Thanos if the attached license is valid, and maintains a whitelist and blacklist pair for each tenant.</p><p>License validation is simple. The ingress binary has a store of public keys and checks to see if the JWT was signed by one of those keys. If the signature is good and the license is not past its expiration date, it&rsquo;s considered valid. We cache successful validations to avoid paying the validation cost each time a payload is received. If an invalid license is detected, the egress binary is told to keep the payload and try again. This is to not lose metrics in cases like a license lapsing and then being renewed the next day. Requests with valid licenses will have their payloads forwarded to Thanos and the reply will be sent back to the egress binary so it can decide what to do with the payload.</p><p>The <code>thanos-tenant</code> HTTP header in the request to Thanos is set to the tenant ID derived from the customer license. Under the hood, Thanos stores each tenant&rsquo;s data in a separate TSDB (time series database). This is great for addressing any concerns with mixing customer data, and it also means queries for a given tenant only need to search through the data for that tenant.</p><p>When the egress binary requests a whitelist and blacklist pair, it also includes a copy of the customer&rsquo;s license. The ingress binary will check to see if a pair exists for the tenant and return it if so. If we haven&rsquo;t set up a specific pair for a tenant, then a default is returned. The whitelist and blacklist pairs are just files on disk with deterministic names. Like many other places in this system, a cache here is used to avoid the cost of repeated lookups.</p><h2 class="relative group">Thanos<div id=thanos class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#thanos aria-label=Anchor>#</a></span></h2><p>We&rsquo;ve now seen how data arrives at Thanos, but so far I&rsquo;ve abstracted Thanos away as a single entity. In reality, Thanos is a collection of processes that work together. Let&rsquo;s zoom in on the Thanos box we&rsquo;ve seen in the diagrams so far and look at what I actually set up.</p><h3 class="relative group">Plumbing<div id=plumbing class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#plumbing aria-label=Anchor>#</a></span></h3><p><figure><img class="my-0 rounded-md" loading=lazy decoding=async fetchpriority=auto alt="Metrics flow into Thanos" width=2182 height=1082 src=/projects/metrics_pipeline/thanos_overview_hu_b0777b0b7ab4a562.png srcset="/projects/metrics_pipeline/thanos_overview_hu_b0777b0b7ab4a562.png 800w, /projects/metrics_pipeline/thanos_overview_hu_ef31c8017e622a02.png 1280w" sizes="(min-width: 768px) 50vw, 65vw" data-zoom-src=/projects/metrics_pipeline/thanos_overview.png></figure></p><p>Heimdall Ingress sends RWP payloads to the Thanos Router. The router is a lightweight and stateless process that distributes metrics to the Thanos Ingestors. It&rsquo;s aware of the ingestors via its configuration file and uses a hashing algorithm to determine which ingestor to send any given metric to. As a side note, one should opt for the <code>ketama</code> hashing algorithm as it&rsquo;s a stable hashing algorithm and allows for simple horizontal scaling of Thanos Receivers.</p><p>The Thanos Ingestors are, in effect, small Prometheus servers. They each maintain a local TSDB and store metrics they receive from the Thanos Router. Every two hours each ingestor uploads a block of data for the last two hours into object storage (AWS S3 in our case). The routers and ingestors are actually the same Thanos process (<code>thanos receive</code>), but take on different responsibilities based on their configuration. It is possible to have one process be both a router and an ingestor, but I chose to break things out into separate processes because the ingestors do significantly more work than the router and that&rsquo;s where I will want to scale. Annoyingly, the <a href=https://thanos.io/tip/components/receive.md/ target=_blank>documentation</a> for <code>thanos receive</code> does not make it clear at all (at least at the time of writing this) that one could make the process behave as an ingestor only, but I found a <a href=https://thanos.io/blog/2023-11-20-life-of-a-sample-part-1/ target=_blank>blog post</a> on the Thanos website that outlined how to do it.</p><p>The Thanos Compactor has two responsibilities: to compact blocks uploaded to object storage and to downsample data. How Prometheus blocks work is out of scope for what I want to discuss here, but in general you can assume fewer blocks means less storage used, quicker lookups, and better indices. Downsampling also plays an important role in performance. For example, if one is visualizing a metric over a whole month, it is very unlikely full resolution for that metric is needed - samples with one hour resolution usually do just as well as samples with one minute resolution.</p><p>Retrieving data from the object store is handled by the Thanos Store component. It pulls down the appropriate blocks from object storage to its local disk and executes the query against that data.</p><p>Queries for metrics first land at the Thanos Query component. The result set that Thanos Query sends back for a given query is the union of the result sets from applying that query to the data in each ingestor&rsquo;s local TSDB, and the data in object storage (via Thanos Store). Remember that metrics are sent to different ingestors based on their hash value, so the data on all ingestors must be scanned to produce the correct result set.</p><h3 class="relative group">Scalability and Performance<div id=scalability-and-performance class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#scalability-and-performance aria-label=Anchor>#</a></span></h3><p>The mothership is where all scalability concerns are. The customer-side components (Prometheus and Heimdall Egress) were able to handle the load of our internal Kubernetes cluster that has hundreds of instances running; a typical Yellowbrick deployment will have fewer than ten instances running.</p><p>To scale the write side of this system, we need to target the router and the ingestors. The ingestors would be the first that need to scale as they do significantly more work than the router. Thankfully, they can scale horizontally and even run on other virtual machines. The router would eventually need to scale horizontally too, but at a much slower pace than the ingestors since the router does so little work (relatively speaking). All of the back pressure in the system is here as well. Each Heimdall Egress binary out in the wild will only have a handful of parallel connections open to the mothership, and they will only send more data as they get back confirmations from Thanos (via Heimdall Ingress). This means the rate at which this system can ingest data will be limited by how well we scale the routers and ingestors, and how fast the ingestors&rsquo; disks are.</p><p>Scaling on the read side is affected by how well the Thanos Store component scales, but also how the ingestors scale. Recall that the data we get back for a query comes from both the store component and the ingestors. The store component scales horizontally and can run on different virtual machines. There are a couple of broad ways to scale the store component (hashed vs replica), but we hadn&rsquo;t hit the need for it, so I could only speculate on what would be most appropriate for this system. The read rate is then limited by:</p><ul><li>The compute power of the ingestor and store components.</li><li>The disk speed of the ingestor and store components.</li><li>The bandwidth between the store components and the object storage.</li></ul><p>We had no real concerns about the bandwidth between Thanos Store and object storage - the mothership is a virtual machine in AWS and we use their S3 service. The compute power and disk speed for the ingestor and store components can be practically scaled out by converting the mothership to be a collection of virtual machines, which presents no real technical challenges, we just haven&rsquo;t needed to go that far yet.</p><p>The Thanos topology I presented above has so far worked very well for Yellowbrick. Data for thousands of instances is flowing in and engineers are able to observe all corresponding systems in real time. Neither CPU, memory, nor disk are overly taxed on the mothership, which is running on a mid-size virtual machine. This design should scale to meet the organization&rsquo;s needs for years to come. If we were to scale to millions of tenants the system design would need to be reconsidered, but that&rsquo;s a welcome problem of success. Our resources weren&rsquo;t infinite, so we focused on something practical we could get going sooner rather than later, while still reasonably accommodating future growth.</p><h2 class="relative group">Grafana<div id=grafana class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#grafana aria-label=Anchor>#</a></span></h2><p>The primary way we expected customers and engineers to interact with the system was via Grafana. The main point of this post is about the metrics pipeline itself, but I did want to touch on Grafana a bit as the dashboards are the most tangible result others would see of our work.</p><p>From the very start, we committed to having the dashboards our customers saw be first-class citizens - they needed to be useful and polished. We felt the best way to ensure this was to dogfood them. The dashboards we used internally for engineers, support staff, etc., were the same dashboards we shipped to our customers. To make the dashboards useful when querying across all of our tenants, I created a script that would modify each dashboard to have an extra Grafana variable (i.e., a dropdown at the top of the dashboard) to select the tenant we were interested in. I used a <a href=https://pkg.go.dev/github.com/prometheus/prometheus/promql/parser target=_blank>Golang library</a> to parse the PromQL queries for each of the visualizations and add <code>tenant_id="TENANT_OF_INTEREST"</code> to each query - when this label is set Thanos will only scan the matching TSDB. Other than that, the internal and customer dashboards were functionally and visually equivalent.</p><p>Releasing the dashboards internally was a very rewarding experience. Very quickly I started to get bug reports, requests for new visualizations, and questions about how to add new metrics to the product. This told me others were getting value out of it right away - the best tools are the tools that actually get used.</p><h2 class="relative group">Conclusion<div id=conclusion class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none"><a class="text-primary-300 dark:text-neutral-700 !no-underline" href=#conclusion aria-label=Anchor>#</a></span></h2><p>We set out to solve two broad problems:</p><ul><li>Provide customers with measurable insight and observability into the product.</li><li>Capture health and diagnostic data for all Yellowbrick systems in near real-time.</li></ul><p>To do that, we built an observability stack using Prometheus, Thanos, Grafana, and a pair of home-grown binaries called Heimdall. We kept resource overhead at customer sites low, and used battle-tested off-the-shelf software to get the project off the ground as quickly as possible. As a quick summary, the system we created:</p><ul><li>Enforces licensing.</li><li>Allows us to dynamically select what metrics to collect per tenant.</li><li>Scales in a predictable way as load increases.</li><li>Keeps metrics data safe in failure conditions.</li><li>Provides both customers and engineers with a well-known interface for turning raw metrics into actionable insight.</li></ul><p>We designed and built this system to scale with the company&rsquo;s needs as we understood them at the time, and it has proven capable of doing so. Startups (and most companies) don&rsquo;t have the luxury of building for every hypothetical future, so we focused on what we actually knew, and built something quickly (but without sacrificing quality).</p><p>It was a real pleasure to work on this project. I got to touch essentially every part of the core stack, interact with engineers and stakeholders across the whole company, and do some exciting greenfield work. In my opinion, it was one of the most interesting engineering projects happening in the company, and I&rsquo;m thankful I got to be one of the driving forces moving it forward. For those of you that made it this far, thanks for reading!</p></div></div><script type=text/javascript src=/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA==" data-oid=views_projects/metrics_pipeline/index.md data-oid-likes=likes_projects/metrics_pipeline/index.md></script></section><footer class="pt-8 max-w-prose print:hidden"></footer></article><div id=scroll-to-top class="fixed bottom-24 end-6 z-50 transform translate-y-4 opacity-0 duration-200"><a href=#the-top class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2026
James Robb</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500" data-url=http://jamesrobb.ca/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>